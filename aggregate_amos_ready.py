#!/usr/bin/env python3
# aggregate_and_prepare_stats.py - è‡ªåŠ¨æŸ¥æ‰¾å¹¶æ±‡æ€»å¤šä¸ª seed ç»“æœï¼Œè®¡ç®— MeanÂ±Stdï¼Œ
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â å¹¶ä¸º p-value è®¡ç®—å‡†å¤‡æ ·æœ¬çº§èšåˆæ•°æ®

import os
import re # ç”¨äºè§£ææ–‡ä»¶å†…å®¹ (å¦‚æœéœ€è¦ï¼Œç›®å‰æ˜¯ç›´æ¥ç”¨ pandas è¯»å–)
import numpy as np
import pandas as pd
import argparse
import glob # ç”¨äºæ–‡ä»¶æŸ¥æ‰¾
from tqdm import tqdm

# --- é…ç½®åŒº ---
# AMOS ç±»åˆ«å (è¯·æ ¹æ®æ‚¨çš„æ•°æ®é›†å’Œ eval_metrics.py è„šæœ¬è°ƒæ•´)
# ç¤ºä¾‹ï¼šAMOS
CLASS_NAMES = [
    'spleen', 'right kidney', 'left kidney', 'gallbladder', 'esophagus',
    'liver', 'stomach', 'aorta', 'inferior vena cava', 'pancreas',
    'right adrenal gland', 'left adrenal gland', 'duodenum', 'bladder', 'prostate/uterus'
]
# ç¤ºä¾‹ï¼šWORD (å¦‚æœæ‚¨çš„ eval_metrics.py è¾“å‡ºäº†è¿™äº›ç±»åˆ«åå¯¹åº”çš„åˆ—)
# CLASS_NAMES = [
# Â  Â  'liver', 'spleen', 'kidney L', 'kidney R', 'stomach', 'gallbladder', 'esophagus',
# Â  Â  'pancreas', 'duodenum', 'colon', 'intestine', 'adrenal', 'rectum', 'bladder',
# Â  Â  'femur L', 'femur R'
# ]

NUM_FOREGROUND_CLASSES = len(CLASS_NAMES)

# å®šä¹‰ Tail Classes (ç¡®ä¿åç§°ä¸ CLASS_NAMES åŒ¹é…)
# ç¤ºä¾‹ï¼šAMOS
TAIL_CLASSES = [
    'esophagus',
    'gallbladder',
    'duodenum',
    'right adrenal gland',
    'left adrenal gland'
]
# ç¤ºä¾‹ï¼šWORD (æ ¹æ®å®é™…æƒ…å†µå®šä¹‰)
# TAIL_CLASSES = [
# Â  Â  'gallbladder', 'esophagus', 'duodenum', 'adrenal', 'rectum'
# ]


# --- è¾…åŠ©å‡½æ•° ---
def get_metric_columns(metric_prefix, class_indices):
    """æ ¹æ®æŒ‡æ ‡å‰ç¼€å’Œç±»åˆ«ç´¢å¼•ç”Ÿæˆåˆ—ååˆ—è¡¨"""
    # class_indices æ˜¯ 0-based, ä½†åˆ—åæ˜¯ 1-based (e.g., Dice_Class1)
    return [f"{metric_prefix}_Class{idx + 1}" for idx in class_indices]

# --- ä¸»å‡½æ•° ---
def main(args):
    # --- 1. è‡ªåŠ¨æŸ¥æ‰¾ seed ç»“æœæ–‡ä»¶ ---
    seed_dirs = sorted(glob.glob(os.path.join(args.method_base_dir, args.seed_pattern)))
    result_files_found = []
    for seed_dir in seed_dirs:
        # å…¼å®¹ .csv å’Œ .xlsx
        potential_csv = os.path.join(seed_dir, args.results_filename + ".csv")
        potential_xlsx = os.path.join(seed_dir, args.results_filename + ".xlsx")

        if os.path.exists(potential_csv):
            result_files_found.append(potential_csv)
        elif os.path.exists(potential_xlsx):
            result_files_found.append(potential_xlsx)
        else:
            print(f"âš ï¸ Warning: Results file '{args.results_filename}.(csv/xlsx)' not found in '{seed_dir}'. Skipping this seed directory.")

    if len(result_files_found) < args.min_seeds:
        print(f"âŒ Error: Need at least {args.min_seeds} valid result files, found {len(result_files_found)} matching pattern '{args.seed_pattern}/{args.results_filename}.(csv/xlsx)' in '{args.method_base_dir}'.")
        return

    print(f"ğŸ” Found {len(result_files_found)} result files to aggregate:")
    for fpath in result_files_found:
        print(f" Â - {fpath}")

    # --- 2. è¯»å–æ‰¾åˆ°çš„æ–‡ä»¶ ---
    dfs = []
    valid_seeds_read = 0
    for file_path in result_files_found:
        try:
            if file_path.endswith(".csv"):
                # å°è¯•è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦ï¼Œä»¥é˜²ä¸‡ä¸€ä¸æ˜¯é€—å·
                df = pd.read_csv(file_path, engine='python', sep=None, on_bad_lines='warn')
            elif file_path.endswith(".xlsx"):
                df = pd.read_excel(file_path, engine='openpyxl')
            else:
                print(f"Unsupported file type: {file_path}")
                continue

            # æ›¿æ¢æ— é™å€¼ä¸º NaN
            df.replace([np.inf, -np.inf], np.nan, inplace=True)

            if "Filename" not in df.columns or df["Filename"].duplicated().any():
                print(f"âš ï¸ Warning: File '{file_path}' lacks unique 'Filename' column. Skipping.")
                continue
            df.set_index("Filename", inplace=True)
            dfs.append(df)
            valid_seeds_read += 1
        except Exception as e:
            print(f"âŒ Error reading '{file_path}': {e}")

    # å†æ¬¡æ£€æŸ¥è¯»å–æˆåŠŸçš„æ–‡ä»¶æ•°
    if valid_seeds_read < args.min_seeds:
        print(f"âŒ Error: Successfully read only {valid_seeds_read} files, need at least {args.min_seeds}.")
        return

    # --- 3. æ£€æŸ¥æ ·æœ¬æ˜¯å¦ä¸€è‡´ (åŸºäºç´¢å¼• 'Filename') ---
    base_index = dfs[0].index
    for i in range(1, len(dfs)):
        if not dfs[i].index.equals(base_index):
            print("âŒ Error: Sample filenames (index) mismatch between result files.")
            # å°è¯•æ‰¾åˆ°å…±åŒçš„æ ·æœ¬è¿›è¡Œåˆ†æ
            common_index = base_index.intersection(dfs[i].index)
            if len(common_index) == 0:
                print("âŒ Error: No common samples found between files. Cannot proceed.")
                return
            print(f"âš ï¸ Warning: Found only {len(common_index)} common samples. Proceeding with intersection.")
            base_index = common_index
            # ç­›é€‰æ‰€æœ‰ DataFrame ä»¥åŒ…å«å…±åŒæ ·æœ¬
            dfs = [df.loc[base_index] for df in dfs]

    print(f"âœ… Processing {len(dfs)} result files with {len(base_index)} common samples each.")

    # --- 4. å‡†å¤‡åˆ—å ---
    fg_indices = list(range(NUM_FOREGROUND_CLASSES))
    try:
        # ç¡®ä¿ CLASS_NAMES æ˜¯æœ€æ–°çš„ï¼Œå¹¶ä¸”ä¸ CSV æ–‡ä»¶ä¸­çš„ Class åˆ—å¯¹åº”
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ CLASS_NAMES çš„é¡ºåºä¸ CSV ä¸­ Class1, Class2... çš„é¡ºåºä¸€è‡´
        tail_indices = [CLASS_NAMES.index(name) for name in TAIL_CLASSES if name in CLASS_NAMES]
        if len(tail_indices) != len(TAIL_CLASSES):
             missing = set(TAIL_CLASSES) - set(CLASS_NAMES)
             print(f"âš ï¸ Warning: Some defined tail classes not found in CLASS_NAMES: {missing}")
    except ValueError as e:
        print(f"âŒ Error: Tail class name '{str(e).split()[0]}' not found in CLASS_NAMES.")
        return
    except Exception as e:
        print(f"âŒ An unexpected error occurred while processing class names: {e}")
        return


    cols_fg_dice = get_metric_columns("Dice", fg_indices)
    cols_fg_asd = get_metric_columns("ASD", fg_indices)

    cols_tail_dice = get_metric_columns("Dice", tail_indices)
    cols_tail_asd = get_metric_columns("ASD", tail_indices)

    # --- 5. è®¡ç®—æ¯ä¸ªæ ·æœ¬è·¨ Seed çš„å¹³å‡æŒ‡æ ‡ (ç”¨äº p-value è®¡ç®—) ---
    aggregated_data = pd.DataFrame(index=base_index) # åˆ›å»ºæ–°çš„ DataFrame å­˜å‚¨èšåˆç»“æœ

    metrics_to_aggregate = {
        "Avg_FG_Dice": cols_fg_dice,
        "Avg_FG_ASD": cols_fg_asd,
        # åªæœ‰åœ¨å®šä¹‰äº† tail_indices æ—¶æ‰è®¡ç®—å°¾éƒ¨æŒ‡æ ‡
        **({"Avg_Tail_Dice": cols_tail_dice} if tail_indices else {}),
        **({"Avg_Tail_ASD": cols_tail_asd} if tail_indices else {}),
    }

    print("â³ Calculating per-sample averages across seeds...")
    for agg_metric_name, class_cols in tqdm(metrics_to_aggregate.items(), desc="Aggregating metrics"):
        # ç¡®ä¿åªä½¿ç”¨åœ¨æ‰€æœ‰ DataFrame ä¸­éƒ½å­˜åœ¨çš„åˆ—
        valid_cols_list = []
        for df in dfs:
            existing_cols = [col for col in class_cols if col in df.columns]
            if not existing_cols: # å¦‚æœä¸€ä¸ªdfè¿ä¸€åˆ—éƒ½æ²¡æœ‰ï¼Œåˆ™æ— æ³•è®¡ç®—
                print(f"âš ï¸ Warning: No columns found for metric {agg_metric_name} in one of the seed files. Skipping this metric for per-sample aggregation.")
                aggregated_data[agg_metric_name] = np.nan
                break # è·³å‡ºå†…å±‚å¾ªç¯ï¼Œå¤„ç†ä¸‹ä¸€ä¸ªèšåˆæŒ‡æ ‡
            valid_cols_list.append(existing_cols)
        else: # å¦‚æœ for å¾ªç¯æ­£å¸¸ç»“æŸ (æ²¡æœ‰ break)
            # ä½¿ç”¨å­˜åœ¨çš„åˆ—è¿›è¡Œæå–å’Œå †å 
            try:
                # é‡æ–°ç´¢å¼•ä»¥ç¡®ä¿æ ·æœ¬é¡ºåºä¸€è‡´ï¼Œç„¶åæå–æœ‰æ•ˆåˆ—çš„å€¼
                seed_metric_values = [df.reindex(base_index)[vcc].values for df, vcc in zip(dfs, valid_cols_list)]

                # å †å æˆ 3D NumPy æ•°ç»„: (n_samples, n_classes_for_metric_in_this_seed, n_seeds)
                # æ³¨æ„ï¼šä¸åŒ seed çš„ n_classes å¯èƒ½ä¸åŒï¼ˆå¦‚æœæŸåˆ—å®Œå…¨ç¼ºå¤±ï¼‰
                # æˆ‘ä»¬éœ€è¦å…ˆè®¡ç®—æ¯ä¸ª seed çš„æ ·æœ¬å†…å¹³å‡å€¼ï¼Œå†è·¨ seed å¹³å‡
                sample_means_per_seed = []
                for seed_values in seed_metric_values:
                    # å¯¹æ¯ä¸ªæ ·æœ¬è®¡ç®—è·¨ç±»åˆ«çš„å¹³å‡å€¼ (axis=1)
                    sample_means_per_seed.append(np.nanmean(seed_values, axis=1))

                # ç°åœ¨ sample_means_per_seed æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ shape (n_samples,) çš„æ•°ç»„
                # å°†å®ƒä»¬å †å èµ·æ¥è®¡ç®—æœ€ç»ˆçš„è·¨ seed å¹³å‡å€¼
                stacked_sample_means = np.stack(sample_means_per_seed, axis=-1) # shape: (n_samples, n_seeds)
                final_mean_per_sample = np.nanmean(stacked_sample_means, axis=1) # shape: (n_samples,)

                aggregated_data[agg_metric_name] = final_mean_per_sample

            except Exception as e:
                 print(f"âŒ Error during stacking/averaging for {agg_metric_name}: {e}. Skipping.")
                 aggregated_data[agg_metric_name] = np.nan


    # --- 6. ä¿å­˜èšåˆåçš„æ ·æœ¬çº§æ•°æ®åˆ° CSV (ç”¨äº p-value) ---
    try:
        # ç¡®ä¿å­˜å‚¨è·¯å¾„çš„ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(args.aggregated_csv_output), exist_ok=True)
        aggregated_data.to_csv(args.aggregated_csv_output, float_format='%.6f', na_rep='NaN')
        print(f"\nâœ… Per-sample aggregated metrics saved to: {args.aggregated_csv_output}")
    except Exception as e:
        print(f"\nâŒ Error saving aggregated CSV to '{args.aggregated_csv_output}': {e}")

    # --- 7. è®¡ç®—æœ€ç»ˆçš„ Mean Â± Std (ç”¨äºè®ºæ–‡è¡¨æ ¼) ---
    print("\nğŸ“Š Calculating final Mean Â± Std across seeds...")

    final_results = {} # å­˜å‚¨æœ€ç»ˆçš„ MeanÂ±Std å­—ç¬¦ä¸²

    # a) è®¡ç®— Per-Class æŒ‡æ ‡çš„ MeanÂ±Std (è·¨ Seeds)
    per_class_means_across_seeds = {} # e.g., {"Dice": [seed0_avg_cls1, seed1_avg_cls1, ...]}
    per_class_stds_across_seeds = {}
    
    for metric_prefix in ["Dice", "ASD"]:
        means_for_metric = {} # { "Dice_Class1": [seed0_avg, seed1_avg, seed2_avg], ... }
        for i in range(NUM_FOREGROUND_CLASSES):
            col_name = f"{metric_prefix}_Class{i+1}"
            seed_averages = []
            for df in dfs:
                if col_name in df.columns:
                    # è®¡ç®—è¯¥ seed åœ¨è¯¥ç±»åˆ«ä¸Šçš„å¹³å‡å€¼ (è·¨æ‰€æœ‰æ ·æœ¬)
                    seed_class_mean = np.nanmean(df[col_name])
                    seed_averages.append(seed_class_mean)
                else:
                    seed_averages.append(np.nan) # å¦‚æœæŸ seed ç¼ºå¤±è¯¥åˆ—

            # è¿‡æ»¤æ‰ NaN åå†è®¡ç®—
            valid_seed_averages = [avg for avg in seed_averages if not np.isnan(avg)]
            if len(valid_seed_averages) >= args.min_seeds: # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ç‚¹è®¡ç®— Std
                 # è®¡ç®—è·¨ seed çš„å‡å€¼å’Œæ ‡å‡†å·®
                 per_class_means_across_seeds.setdefault(metric_prefix, {})[col_name] = np.nanmean(valid_seed_averages)
                 per_class_stds_across_seeds.setdefault(metric_prefix, {})[col_name] = np.nanstd(valid_seed_averages)
            else:
                 # æ•°æ®ç‚¹ä¸è¶³ï¼Œæ ‡è®°ä¸º NaN
                 per_class_means_across_seeds.setdefault(metric_prefix, {})[col_name] = np.nan
                 per_class_stds_across_seeds.setdefault(metric_prefix, {})[col_name] = np.nan


    # b) è®¡ç®— Overall å’Œ Tail Avg æŒ‡æ ‡çš„æœ€ç»ˆ MeanÂ±Std (è·¨ Seeds)
    # Â  Â æˆ‘ä»¬éœ€è¦å…ˆè®¡ç®—å‡ºæ¯ä¸ª seed çš„ Overall/Tail å¹³å‡å€¼
    seed_level_aggregates = {agg_metric: [] for agg_metric in aggregated_data.columns}

    for df in dfs: # éå†æ¯ä¸ª seed çš„ DataFrame
        # ç¡®ä¿ DataFrame ç´¢å¼•ä¸ base_index ä¸€è‡´ (å¦‚æœä¹‹å‰åšäº†äº¤é›†å¤„ç†)
        df_reindexed = df.reindex(base_index)
        for agg_metric_name, class_cols in metrics_to_aggregate.items():
            valid_cols = [col for col in class_cols if col in df_reindexed.columns]
            if not valid_cols:
                seed_level_aggregates[agg_metric_name].append(np.nan)
                continue
            # è®¡ç®—è¯¥ seed åœ¨æ‰€æœ‰æ ·æœ¬ä¸Šï¼Œè·¨æŒ‡å®šç±»åˆ«çš„å¹³å‡å€¼
            # 1. å…ˆè®¡ç®—æ¯ä¸ªæ ·æœ¬è·¨ç±»åˆ«çš„å¹³å‡å€¼
            sample_means = np.nanmean(df_reindexed[valid_cols].values, axis=1)
            # 2. å†è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼
            seed_overall_mean = np.nanmean(sample_means)
            seed_level_aggregates[agg_metric_name].append(seed_overall_mean)

    # ç°åœ¨ seed_level_aggregates åŒ…å«äº†æ¯ä¸ªèšåˆæŒ‡æ ‡çš„ seed çº§åˆ«å¹³å‡å€¼åˆ—è¡¨
    for agg_metric_name, seed_means in seed_level_aggregates.items():
        valid_seed_means = [m for m in seed_means if not np.isnan(m)]
        if len(valid_seed_means) >= args.min_seeds:
            final_mean = np.nanmean(valid_seed_means)
            final_std = np.nanstd(valid_seed_means) # <--- æ­£ç¡®çš„æ ‡å‡†å·®ï¼

            # æ ¼å¼åŒ–è¾“å‡º
            if "Dice" in agg_metric_name:
                 final_results[agg_metric_name] = f"{final_mean*100:.2f} Â± {final_std*100:.2f}"
            else: # ASD ä¿ç•™ 3 ä½å°æ•°
                 final_results[agg_metric_name] = f"{final_mean:.3f} Â± {final_std:.3f}"
        else:
            final_results[agg_metric_name] = 'N/A' # æ•°æ®ç‚¹ä¸è¶³

    # --- 8. è¾“å‡ºæœ€ç»ˆ Mean Â± Std ç»“æœåˆ°æ–‡ä»¶ ---
    try:
        # ç¡®ä¿å­˜å‚¨è·¯å¾„çš„ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(args.summary_output), exist_ok=True)
        with open(args.summary_output, 'w') as f:
            f.write(f"ğŸ“Š Aggregated Summary Results (Mean Â± Std from {len(dfs)} seeds)\n")
            f.write(f"Method Base Directory: {args.method_base_dir}\n")
            f.write("="*70 + "\n\n")

            # --- Per-Class Metrics (ä½¿ç”¨æ–°çš„è®¡ç®—ç»“æœ) ---
            f.write("ğŸ”· Per-Class Metrics:\n")
            f.write("-" * 50 + "\n")
            
            # --- ä¿®æ”¹äº†è¡¨å¤´å’Œæ ¼å¼ ---
            header_format = f"{{:<{args.class_name_width}}} | {{:<18}} | {{:<18}}"
            row_format = f"{{:<{args.class_name_width}}} | {{:>18}} | {{:>18}}"
            f.write(header_format.format('Class', 'Dice (%)', 'ASD (mm)') + "\n")
            f.write("-" * (args.class_name_width + 40) + "\n") # è°ƒæ•´äº†åˆ†éš”çº¿é•¿åº¦

            for i, class_name in enumerate(CLASS_NAMES):
                # ä»å­—å…¸ä¸­å®‰å…¨åœ°è·å–è·¨ seed çš„å‡å€¼å’Œæ ‡å‡†å·®
                col_name_dice = f"Dice_Class{i+1}"
                dice_mean = per_class_means_across_seeds.get("Dice", {}).get(col_name_dice, np.nan) * 100
                dice_std = per_class_stds_across_seeds.get("Dice", {}).get(col_name_dice, np.nan) * 100

                col_name_asd = f"ASD_Class{i+1}"
                asd_mean = per_class_means_across_seeds.get("ASD", {}).get(col_name_asd, np.nan)
                asd_std = per_class_stds_across_seeds.get("ASD", {}).get(col_name_asd, np.nan)

                dice_str = f"{dice_mean:5.2f} Â± {dice_std:5.2f}" if not np.isnan(dice_mean) else "N/A"
                asd_str = f"{asd_mean:5.3f} Â± {asd_std:5.3f}" if not np.isnan(asd_mean) else "N/A"

                # --- ä¿®æ”¹äº† f.write ---
                f.write(row_format.format(class_name, dice_str, asd_str) + "\n")
            f.write("-" * (args.class_name_width + 40) + "\n\n") # è°ƒæ•´äº†åˆ†éš”çº¿é•¿åº¦

            # --- Overall & Tail Averages (ä½¿ç”¨æ–°çš„è®¡ç®—ç»“æœ) ---
            f.write("ğŸ”· Overall & Tail Average Metrics:\n")
            f.write("-" * 50 + "\n")
            f.write(f"{'Metric':<22} | {'Value (Mean Â± Std)'}\n")
            f.write("-" * 50 + "\n")
            f.write(f"{'Avg Foreground Dice':<22} | {final_results.get('Avg_FG_Dice', 'N/A')}\n")
            f.write(f"{'Avg Foreground ASD':<22} | {final_results.get('Avg_FG_ASD', 'N/A')}\n")
            f.write("-" * 50 + "\n")
            if tail_indices:
                f.write(f"{'Avg Tail Dice':<22} | {final_results.get('Avg_Tail_Dice', 'N/A')}\n")
                f.write(f"{'Avg Tail ASD':<22} | {final_results.get('Avg_Tail_ASD', 'N/A')}\n")
                f.write("-" * 50 + "\n")
                f.write("\nğŸ“Œ Tail Classes: " + ", ".join(TAIL_CLASSES) + "\n")

        print(f"âœ… Final summary results saved to: {args.summary_output}")

    except Exception as e:
        print(f"\nâŒ Error writing summary file '{args.summary_output}': {e}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        # --- ä¿®æ”¹äº†æè¿° ---
        description="Aggregate per-sample results from multiple seeds found in a directory structure. Calculates MeanÂ±Std (Dice, ASD) for tables and prepares aggregated per-sample data for p-value testing.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    # --- è¾“å…¥å‚æ•° ---
    parser.add_argument('--method_base_dir', type=str, required=True,
                        help='Path to the base directory of the method (e.g., ./logs/amos/cps/). Contains subdirectories for each seed.')
    parser.add_argument('--seed_pattern', type=str, default='seed_*',
                        help='Pattern to find seed directories within the base directory (e.g., seed_*, run_*).')
    parser.add_argument('--results_filename', type=str, default='result',
                        help='Base name of the result file (WITHOUT extension) within each seed directory (e.g., result for result.csv or result.xlsx).')

    # --- è¾“å‡ºå‚æ•° ---
    parser.add_argument('--aggregated_csv_output', type=str, required=True,
                        help='Path to save the NEW CSV containing per-sample results averaged across seeds (input for p-value script).')
    parser.add_argument('--summary_output', type=str, default='aggregated_summary.txt',
                        help='Path to save the final Mean Â± Std summary text file (for paper table).')

    # --- æ§åˆ¶å‚æ•° ---
    parser.add.argument('--min_seeds', type=int, default=2,
                        help='Minimum number of valid seed result files required to proceed.')
    parser.add_argument('--class_name_width', type=int, default=22,
                         help='Width for the class name column in the summary output file for alignment.')

    args = parser.parse_args()

    # --- è¿è¡Œä¸»å‡½æ•° ---
    main(args)